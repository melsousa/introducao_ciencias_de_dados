{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QCgCHgw4ICUC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(188264, 4)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../lista_5/dataset/mensagens_com_frequencia_e_texto_processado.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto_original</th>\n",
              "      <th>frequencia</th>\n",
              "      <th>texto_limpo</th>\n",
              "      <th>text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>▪️ 01/11/2022 - 08:00 \\n\\nÁsia-Pacífico (fecha...</td>\n",
              "      <td>10</td>\n",
              "      <td>01112022 0800 asiapacifico fechado spasx 165 6...</td>\n",
              "      <td>01112022 0800 asiapacifico fechado spasx 165 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>*02.10.2022 TSE - Governo-SP às 18h 59m 00s*</td>\n",
              "      <td>8</td>\n",
              "      <td>02102022 tse governosp as 18h 59m 00s</td>\n",
              "      <td>02102022 tse governosp 18h 59m 00s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>02.10.2022 TSE - Governo-SP às 20h 10m 35s</td>\n",
              "      <td>4</td>\n",
              "      <td>02102022 tse governosp as 20h 10m 35s</td>\n",
              "      <td>02102022 tse governosp 20h 10m 35s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02.10.2022 TSE - Presidente - às 18h 55m 31s</td>\n",
              "      <td>10</td>\n",
              "      <td>02102022 tse presidente as 18h 55m 31s</td>\n",
              "      <td>02102022 tse presidente 18h 55m 31s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*02.10.2022 TSE - Presidente às 20h 02m 45s*</td>\n",
              "      <td>3</td>\n",
              "      <td>02102022 tse presidente as 20h 02m 45s</td>\n",
              "      <td>02102022 tse presidente 20h 02m 45s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      texto_original  frequencia  \\\n",
              "0  ▪️ 01/11/2022 - 08:00 \\n\\nÁsia-Pacífico (fecha...          10   \n",
              "1       *02.10.2022 TSE - Governo-SP às 18h 59m 00s*           8   \n",
              "2         02.10.2022 TSE - Governo-SP às 20h 10m 35s           4   \n",
              "3       02.10.2022 TSE - Presidente - às 18h 55m 31s          10   \n",
              "4       *02.10.2022 TSE - Presidente às 20h 02m 45s*           3   \n",
              "\n",
              "                                         texto_limpo  \\\n",
              "0  01112022 0800 asiapacifico fechado spasx 165 6...   \n",
              "1              02102022 tse governosp as 18h 59m 00s   \n",
              "2              02102022 tse governosp as 20h 10m 35s   \n",
              "3             02102022 tse presidente as 18h 55m 31s   \n",
              "4             02102022 tse presidente as 20h 02m 45s   \n",
              "\n",
              "                                      text_processed  \n",
              "0  01112022 0800 asiapacifico fechado spasx 165 6...  \n",
              "1                 02102022 tse governosp 18h 59m 00s  \n",
              "2                 02102022 tse governosp 20h 10m 35s  \n",
              "3                02102022 tse presidente 18h 55m 31s  \n",
              "4                02102022 tse presidente 20h 02m 45s  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(188263, 4)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Excluir as linhas onde 'text_processed' é nula, modificando o dataframe original\n",
        "df.dropna(subset=['text_processed'], inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(183300, 4)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[df['text_processed'].str.strip().str.split().apply(lambda x: len([w for w in x if w])) >= 5]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Melissa Felipe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gerando embeddings em batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 37/37 [1:33:19<00:00, 151.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Comparando vetores por similaridade...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 183300/183300 [44:02:46<00:00,  1.16it/s]        \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Total de mensagens finais: 175436\n",
            "  Mensagens removidas por similaridade: 7864\n",
            "\n",
            "Total de pares similares encontrados: 7864\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Codificando os textos ---\n",
        "modelo_bert = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "batch_size = 5000\n",
        "vetores = []\n",
        "print(\"Gerando embeddings em batches...\")\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    batch_textos = df['text_processed'].iloc[i:i + batch_size].tolist()\n",
        "    batch_vetores = modelo_bert.encode(batch_textos, show_progress_bar=False)\n",
        "    vetores.extend(batch_vetores)\n",
        "\n",
        "df['vector'] = vetores\n",
        "\n",
        "\n",
        "\n",
        "# Parâmetro de similaridade\n",
        "limiar_similaridade = 0.90\n",
        "janela = 1000  # K Vizinhos mais proxímos\n",
        "\n",
        "# Inicialização\n",
        "indices_para_remover = set()\n",
        "agrupamento = defaultdict(list)\n",
        "\n",
        "print(\" Comparando vetores por similaridade...\")\n",
        "\n",
        "# Comparar vetores usando cosine_similarity em janela\n",
        "for i in tqdm(range(len(df))):\n",
        "    if i in indices_para_remover:\n",
        "        continue\n",
        "    vec_i = np.array(df.iloc[i]['vector']).reshape(1, -1)\n",
        "    for j in range(i + 1, min(i + janela, len(df))):\n",
        "        if j in indices_para_remover:\n",
        "            continue\n",
        "        vec_j = np.array(df.iloc[j]['vector']).reshape(1, -1)\n",
        "        sim = cosine_similarity(vec_i, vec_j)[0][0]\n",
        "        if sim >= limiar_similaridade:\n",
        "            agrupamento[i].append(j)\n",
        "            indices_para_remover.add(j)\n",
        "\n",
        "# Soma frequência das mensagens agrupadas\n",
        "linhas_resultado = []\n",
        "mensagens_utilizadas = set()\n",
        "\n",
        "for idx_base, similares_idxs in agrupamento.items():\n",
        "    if idx_base in mensagens_utilizadas:\n",
        "        continue\n",
        "    freq_total = df.iloc[idx_base]['frequencia']\n",
        "    mensagens_utilizadas.add(idx_base)\n",
        "\n",
        "    for sim_idx in similares_idxs:\n",
        "        freq_total += df.iloc[sim_idx]['frequencia']\n",
        "        mensagens_utilizadas.add(sim_idx)\n",
        "\n",
        "    linha = df.iloc[idx_base].copy()\n",
        "    linha['frequencia'] = freq_total\n",
        "    linhas_resultado.append(linha)\n",
        "\n",
        "# Mensagens que não foram agrupadas\n",
        "indices_restantes = set(range(len(df))) - mensagens_utilizadas\n",
        "df_restantes = df.iloc[list(indices_restantes)].copy()\n",
        "\n",
        "# Resultado final\n",
        "df_resultado = pd.DataFrame(linhas_resultado)\n",
        "df_final_total = pd.concat([df_resultado, df_restantes], ignore_index=True)\n",
        "\n",
        "print(f\"\\n Total de mensagens finais: {len(df_final_total)}\")\n",
        "print(f\"  Mensagens removidas por similaridade: {len(indices_para_remover)}\")\n",
        "\n",
        "# --- Criar DataFrame com mensagens similares lado a lado ---\n",
        "pares_similares = []\n",
        "\n",
        "for idx_base, similares_idxs in agrupamento.items():\n",
        "    texto_base = df.at[idx_base, 'text_processed']\n",
        "    vetor_base = df.at[idx_base, 'vector']\n",
        "    freq_base = df.at[idx_base, 'frequencia']\n",
        "\n",
        "    for sim_idx in similares_idxs:\n",
        "        texto_similar = df.at[sim_idx, 'text_processed']\n",
        "        vetor_similar = df.at[sim_idx, 'vector']\n",
        "        freq_similar = df.at[sim_idx, 'frequencia']\n",
        "        similaridade = cosine_similarity(\n",
        "            np.array(vetor_base).reshape(1, -1),\n",
        "            np.array(vetor_similar).reshape(1, -1)\n",
        "        )[0][0]\n",
        "\n",
        "        if similaridade >= limiar_similaridade:\n",
        "          pares_similares.append({\n",
        "                'mensagem_base': texto_base,\n",
        "                'frequencia_base': freq_base,\n",
        "                'mensagem_similar': texto_similar,\n",
        "                'frequencia_similar': freq_similar,\n",
        "                'similaridade': round(similaridade, 4)\n",
        "            })\n",
        "\n",
        "# Criar o DataFrame final com os pares similares\n",
        "df_pares_similares = pd.DataFrame(pares_similares)\n",
        "\n",
        "print(f\"\\nTotal de pares similares encontrados: {len(df_pares_similares)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mensagem_base</th>\n",
              "      <th>frequencia_base</th>\n",
              "      <th>mensagem_similar</th>\n",
              "      <th>frequencia_similar</th>\n",
              "      <th>similaridade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01112022 0800 asiapacifico fechado spasx 165 6...</td>\n",
              "      <td>10</td>\n",
              "      <td>11102022 0800 asiapacifico fechado spasx 034 6...</td>\n",
              "      <td>8</td>\n",
              "      <td>0.9853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01112022 0800 asiapacifico fechado spasx 165 6...</td>\n",
              "      <td>10</td>\n",
              "      <td>11112022 0800 asiapacifico fechado spasx 279 7...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01112022 0800 asiapacifico fechado spasx 165 6...</td>\n",
              "      <td>10</td>\n",
              "      <td>14102022 0800 asiapacifico fechado spasx 175 6...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02102022 tse governosp 18h 59m 00s</td>\n",
              "      <td>8</td>\n",
              "      <td>02102022 tse governosp 20h 10m 35s</td>\n",
              "      <td>4</td>\n",
              "      <td>0.9196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02102022 tse presidente 18h 55m 31s</td>\n",
              "      <td>10</td>\n",
              "      <td>02102022 tse presidente 20h 02m 45s</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>02102022 tse presidente 18h 55m 31s</td>\n",
              "      <td>10</td>\n",
              "      <td>02102022 tse presidente 22h 21m 36s</td>\n",
              "      <td>2</td>\n",
              "      <td>0.9672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0516 02112022 ricardo jornalista 2 entenda dif...</td>\n",
              "      <td>125</td>\n",
              "      <td>111 0710 sub ten picanco ferreira entenda dife...</td>\n",
              "      <td>39</td>\n",
              "      <td>0.9824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>08112022 0000 asiapacifico spasx 025 695080 ni...</td>\n",
              "      <td>5</td>\n",
              "      <td>abertura 01112022 2240 abertura asiapacifico s...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>08112022 0000 asiapacifico spasx 025 695080 ni...</td>\n",
              "      <td>5</td>\n",
              "      <td>abertura 10102022 2240 abertura asiapacifico s...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.9024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>08112022 0000 asiapacifico spasx 025 695080 ni...</td>\n",
              "      <td>5</td>\n",
              "      <td>abertura 20102022 2240 abertura asiapacifico s...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.9058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       mensagem_base  frequencia_base  \\\n",
              "0  01112022 0800 asiapacifico fechado spasx 165 6...               10   \n",
              "1  01112022 0800 asiapacifico fechado spasx 165 6...               10   \n",
              "2  01112022 0800 asiapacifico fechado spasx 165 6...               10   \n",
              "3                 02102022 tse governosp 18h 59m 00s                8   \n",
              "4                02102022 tse presidente 18h 55m 31s               10   \n",
              "5                02102022 tse presidente 18h 55m 31s               10   \n",
              "6  0516 02112022 ricardo jornalista 2 entenda dif...              125   \n",
              "7  08112022 0000 asiapacifico spasx 025 695080 ni...                5   \n",
              "8  08112022 0000 asiapacifico spasx 025 695080 ni...                5   \n",
              "9  08112022 0000 asiapacifico spasx 025 695080 ni...                5   \n",
              "\n",
              "                                    mensagem_similar  frequencia_similar  \\\n",
              "0  11102022 0800 asiapacifico fechado spasx 034 6...                   8   \n",
              "1  11112022 0800 asiapacifico fechado spasx 279 7...                   3   \n",
              "2  14102022 0800 asiapacifico fechado spasx 175 6...                   3   \n",
              "3                 02102022 tse governosp 20h 10m 35s                   4   \n",
              "4                02102022 tse presidente 20h 02m 45s                   3   \n",
              "5                02102022 tse presidente 22h 21m 36s                   2   \n",
              "6  111 0710 sub ten picanco ferreira entenda dife...                  39   \n",
              "7  abertura 01112022 2240 abertura asiapacifico s...                  10   \n",
              "8  abertura 10102022 2240 abertura asiapacifico s...                   4   \n",
              "9  abertura 20102022 2240 abertura asiapacifico s...                   2   \n",
              "\n",
              "   similaridade  \n",
              "0        0.9853  \n",
              "1        0.9688  \n",
              "2        0.9840  \n",
              "3        0.9196  \n",
              "4        0.9730  \n",
              "5        0.9672  \n",
              "6        0.9824  \n",
              "7        0.9260  \n",
              "8        0.9024  \n",
              "9        0.9058  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pares_similares.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(175436, 5)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final_total.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segunda rodada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_segunda_rodada = df_final_total.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gerando embeddings em batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:49<00:00, 24.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Comparando vetores por similaridade...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9310/9310 [29:20<00:00,  5.29it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Total de mensagens finais: 9220\n",
            "  Mensagens removidas por similaridade: 90\n",
            "\n",
            "Total de pares similares encontrados: 90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Codificando os textos ---\n",
        "modelo_bert = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "df_segunda_rodada = df_segunda_rodada.reset_index(drop=True)\n",
        "\n",
        "batch_size = 5000\n",
        "vetores = []\n",
        "print(\"Gerando embeddings em batches...\")\n",
        "for i in tqdm(range(0, len(df_segunda_rodada), batch_size)):\n",
        "    batch_textos = df_segunda_rodada['text_processed'].iloc[i:i + batch_size].tolist()\n",
        "    batch_vetores = modelo_bert.encode(batch_textos, show_progress_bar=False)\n",
        "    vetores.extend(batch_vetores)\n",
        "\n",
        "df_segunda_rodada['vector'] = vetores\n",
        "\n",
        "\n",
        "\n",
        "# Parâmetro de similaridade\n",
        "limiar_similaridade = 0.90\n",
        "janela = 1000  # reduz custo computacional\n",
        "\n",
        "# Inicialização\n",
        "indices_para_remover = set()\n",
        "agrupamento = defaultdict(list)\n",
        "\n",
        "print(\" Comparando vetores por similaridade...\")\n",
        "\n",
        "# Comparar vetores usando cosine_similarity em janela\n",
        "for i in tqdm(range(len(df_segunda_rodada))):\n",
        "    if i in indices_para_remover:\n",
        "        continue\n",
        "    vec_i = np.array(df_segunda_rodada.iloc[i]['vector']).reshape(1, -1)\n",
        "    for j in range(i + 1, min(i + janela, len(df_segunda_rodada))):\n",
        "        if j in indices_para_remover:\n",
        "            continue\n",
        "        vec_j = np.array(df_segunda_rodada.iloc[j]['vector']).reshape(1, -1)\n",
        "        sim = cosine_similarity(vec_i, vec_j)[0][0]\n",
        "        if sim >= limiar_similaridade:\n",
        "            agrupamento[i].append(j)\n",
        "            indices_para_remover.add(j)\n",
        "\n",
        "# Soma frequência das mensagens agrupadas\n",
        "linhas_resultado = []\n",
        "mensagens_utilizadas = set()\n",
        "\n",
        "for idx_base, similares_idxs in agrupamento.items():\n",
        "    if idx_base in mensagens_utilizadas:\n",
        "        continue\n",
        "    freq_total = df_segunda_rodada.iloc[idx_base]['frequencia']\n",
        "    mensagens_utilizadas.add(idx_base)\n",
        "\n",
        "    for sim_idx in similares_idxs:\n",
        "        freq_total += df_segunda_rodada.iloc[sim_idx]['frequencia']\n",
        "        mensagens_utilizadas.add(sim_idx)\n",
        "\n",
        "    linha = df_segunda_rodada.iloc[idx_base].copy()\n",
        "    linha['frequencia'] = freq_total\n",
        "    linhas_resultado.append(linha)\n",
        "\n",
        "# Mensagens que não foram agrupadas\n",
        "indices_restantes = set(range(len(df_segunda_rodada))) - mensagens_utilizadas\n",
        "df_restantes = df_segunda_rodada.iloc[list(indices_restantes)].copy()\n",
        "\n",
        "# Resultado final\n",
        "df_resultado = pd.DataFrame(linhas_resultado)\n",
        "df_final_total = pd.concat([df_resultado, df_restantes], ignore_index=True)\n",
        "\n",
        "print(f\"\\n Total de mensagens finais: {len(df_final_total)}\")\n",
        "print(f\"  Mensagens removidas por similaridade: {len(indices_para_remover)}\")\n",
        "\n",
        "# --- Criar DataFrame com mensagens similares lado a lado ---\n",
        "pares_similares = []\n",
        "\n",
        "for idx_base, similares_idxs in agrupamento.items():\n",
        "    texto_base = df_segunda_rodada.at[idx_base, 'text_processed']\n",
        "    vetor_base = df_segunda_rodada.at[idx_base, 'vector']\n",
        "    freq_base = df_segunda_rodada.at[idx_base, 'frequencia']\n",
        "\n",
        "    for sim_idx in similares_idxs:\n",
        "        texto_similar = df_segunda_rodada.at[sim_idx, 'text_processed']\n",
        "        vetor_similar = df_segunda_rodada.at[sim_idx, 'vector']\n",
        "        freq_similar = df_segunda_rodada.at[sim_idx, 'frequencia']\n",
        "        similaridade = cosine_similarity(\n",
        "            np.array(vetor_base).reshape(1, -1),\n",
        "            np.array(vetor_similar).reshape(1, -1)\n",
        "        )[0][0]\n",
        "\n",
        "        if similaridade >= limiar_similaridade:\n",
        "          pares_similares.append({\n",
        "                'mensagem_base': texto_base,\n",
        "                'frequencia_base': freq_base,\n",
        "                'mensagem_similar': texto_similar,\n",
        "                'frequencia_similar': freq_similar,\n",
        "                'similaridade': round(similaridade, 4)\n",
        "            })\n",
        "\n",
        "# Criar o DataFrame final com os pares similares\n",
        "df_pares_similares = pd.DataFrame(pares_similares)\n",
        "\n",
        "print(f\"\\nTotal de pares similares encontrados: {len(df_pares_similares)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mensagem_base</th>\n",
              "      <th>frequencia_base</th>\n",
              "      <th>mensagem_similar</th>\n",
              "      <th>frequencia_similar</th>\n",
              "      <th>similaridade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>noticia deixa triste kwaivideo</td>\n",
              "      <td>2543</td>\n",
              "      <td>noticia deixa triste kwaivideo</td>\n",
              "      <td>147</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acesse link entrar grupo whatsapp chat</td>\n",
              "      <td>209</td>\n",
              "      <td>acesse link entrar grupo whatsapp chat</td>\n",
              "      <td>38</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acesse link entrar grupo whatsapp chat</td>\n",
              "      <td>209</td>\n",
              "      <td>acesse link entrar grupo whatsapp chat</td>\n",
              "      <td>32</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>acesse link entrar grupo whatsapp chat</td>\n",
              "      <td>209</td>\n",
              "      <td>acesse link entrar grupo whatsapp chat</td>\n",
              "      <td>11</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acesse link entrar grupo whatsapp chat</td>\n",
              "      <td>209</td>\n",
              "      <td>acesse link entrar grupo whatsapp chat</td>\n",
              "      <td>14</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            mensagem_base  frequencia_base  \\\n",
              "0          noticia deixa triste kwaivideo             2543   \n",
              "1  acesse link entrar grupo whatsapp chat              209   \n",
              "2  acesse link entrar grupo whatsapp chat              209   \n",
              "3  acesse link entrar grupo whatsapp chat              209   \n",
              "4  acesse link entrar grupo whatsapp chat              209   \n",
              "\n",
              "                         mensagem_similar  frequencia_similar  similaridade  \n",
              "0          noticia deixa triste kwaivideo                 147           1.0  \n",
              "1  acesse link entrar grupo whatsapp chat                  38           1.0  \n",
              "2  acesse link entrar grupo whatsapp chat                  32           1.0  \n",
              "3  acesse link entrar grupo whatsapp chat                  11           1.0  \n",
              "4  acesse link entrar grupo whatsapp chat                  14           1.0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pares_similares.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Terceira rodada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gerando embeddings em batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:51<00:00, 25.77s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Comparando vetores por similaridade...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 1033/9310 [34:46<3:43:05,  1.62s/it]  "
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Codificando os textos ---\n",
        "modelo_bert = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "df_segunda_rodada = df_segunda_rodada.reset_index(drop=True)\n",
        "\n",
        "batch_size = 5000\n",
        "vetores = []\n",
        "print(\"Gerando embeddings em batches...\")\n",
        "for i in tqdm(range(0, len(df_segunda_rodada), batch_size)):\n",
        "    batch_textos = df_segunda_rodada['text_processed'].iloc[i:i + batch_size].tolist()\n",
        "    batch_vetores = modelo_bert.encode(batch_textos, show_progress_bar=False)\n",
        "    vetores.extend(batch_vetores)\n",
        "\n",
        "df_segunda_rodada['vector'] = vetores\n",
        "\n",
        "\n",
        "\n",
        "# Parâmetro de similaridade\n",
        "limiar_similaridade = 0.90\n",
        "janela = 9000  # reduz custo computacional\n",
        "\n",
        "# Inicialização\n",
        "indices_para_remover = set()\n",
        "agrupamento = defaultdict(list)\n",
        "\n",
        "print(\" Comparando vetores por similaridade...\")\n",
        "\n",
        "# Comparar vetores usando cosine_similarity em janela\n",
        "for i in tqdm(range(len(df_segunda_rodada))):\n",
        "    if i in indices_para_remover:\n",
        "        continue\n",
        "    vec_i = np.array(df_segunda_rodada.iloc[i]['vector']).reshape(1, -1)\n",
        "    for j in range(i + 1, min(i + janela, len(df_segunda_rodada))):\n",
        "        if j in indices_para_remover:\n",
        "            continue\n",
        "        vec_j = np.array(df_segunda_rodada.iloc[j]['vector']).reshape(1, -1)\n",
        "        sim = cosine_similarity(vec_i, vec_j)[0][0]\n",
        "        if sim >= limiar_similaridade:\n",
        "            agrupamento[i].append(j)\n",
        "            indices_para_remover.add(j)\n",
        "\n",
        "# Soma frequência das mensagens agrupadas\n",
        "linhas_resultado = []\n",
        "mensagens_utilizadas = set()\n",
        "\n",
        "for idx_base, similares_idxs in agrupamento.items():\n",
        "    if idx_base in mensagens_utilizadas:\n",
        "        continue\n",
        "    freq_total = df_segunda_rodada.iloc[idx_base]['frequencia']\n",
        "    mensagens_utilizadas.add(idx_base)\n",
        "\n",
        "    for sim_idx in similares_idxs:\n",
        "        freq_total += df_segunda_rodada.iloc[sim_idx]['frequencia']\n",
        "        mensagens_utilizadas.add(sim_idx)\n",
        "\n",
        "    linha = df_segunda_rodada.iloc[idx_base].copy()\n",
        "    linha['frequencia'] = freq_total\n",
        "    linhas_resultado.append(linha)\n",
        "\n",
        "# Mensagens que não foram agrupadas\n",
        "indices_restantes = set(range(len(df_segunda_rodada))) - mensagens_utilizadas\n",
        "df_restantes = df_segunda_rodada.iloc[list(indices_restantes)].copy()\n",
        "\n",
        "# Resultado final\n",
        "df_resultado = pd.DataFrame(linhas_resultado)\n",
        "df_final_total = pd.concat([df_resultado, df_restantes], ignore_index=True)\n",
        "\n",
        "print(f\"\\n Total de mensagens finais: {len(df_final_total)}\")\n",
        "print(f\"  Mensagens removidas por similaridade: {len(indices_para_remover)}\")\n",
        "\n",
        "# --- Criar DataFrame com mensagens similares lado a lado ---\n",
        "pares_similares = []\n",
        "\n",
        "for idx_base, similares_idxs in agrupamento.items():\n",
        "    texto_base = df_segunda_rodada.at[idx_base, 'text_processed']\n",
        "    vetor_base = df_segunda_rodada.at[idx_base, 'vector']\n",
        "    freq_base = df_segunda_rodada.at[idx_base, 'frequencia']\n",
        "\n",
        "    for sim_idx in similares_idxs:\n",
        "        texto_similar = df_segunda_rodada.at[sim_idx, 'text_processed']\n",
        "        vetor_similar = df_segunda_rodada.at[sim_idx, 'vector']\n",
        "        freq_similar = df_segunda_rodada.at[sim_idx, 'frequencia']\n",
        "        similaridade = cosine_similarity(\n",
        "            np.array(vetor_base).reshape(1, -1),\n",
        "            np.array(vetor_similar).reshape(1, -1)\n",
        "        )[0][0]\n",
        "\n",
        "        if similaridade >= limiar_similaridade:\n",
        "          pares_similares.append({\n",
        "                'mensagem_base': texto_base,\n",
        "                'frequencia_base': freq_base,\n",
        "                'mensagem_similar': texto_similar,\n",
        "                'frequencia_similar': freq_similar,\n",
        "                'similaridade': round(similaridade, 4)\n",
        "            })\n",
        "\n",
        "# Criar o DataFrame final com os pares similares\n",
        "df_pares_similares = pd.DataFrame(pares_similares)\n",
        "\n",
        "print(f\"\\nTotal de pares similares encontrados: {len(df_pares_similares)}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
