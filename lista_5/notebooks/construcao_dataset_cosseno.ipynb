{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89175ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Etapa 1: Limpeza do texto ---\n",
    "def limpar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"http\\S+\", \"\", texto)\n",
    "    texto = emoji.replace_emoji(texto, '')\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", texto)\n",
    "    texto = unidecode.unidecode(texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "    return texto\n",
    "\n",
    "df['texto_limpo'] = df['texto_original'].apply(limpar_texto)\n",
    "\n",
    "# --- Etapa 2: Embeddings com BERT ---\n",
    "modelo_bert = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "df['vector'] = list(modelo_bert.encode(df['texto_limpo'].tolist(), show_progress_bar=True))\n",
    "\n",
    "# --- Etapa 3: Comparar e consolidar similaridade ---\n",
    "limiar_remocao = 0.85\n",
    "indices_para_remover = set()\n",
    "pares_similares = []\n",
    "\n",
    "# mapeamento de index -> indices duplicados para somar frequência\n",
    "agrupamento_similares = {}\n",
    "\n",
    "print(\"\\nComparando mensagens por similaridade...\")\n",
    "for i in tqdm(range(len(df))):\n",
    "    if i in indices_para_remover:\n",
    "        continue\n",
    "    vec_i = df.iloc[i]['vector']\n",
    "    for j in range(i + 1, len(df)):\n",
    "        if j in indices_para_remover:\n",
    "            continue\n",
    "        vec_j = df.iloc[j]['vector']\n",
    "        sim = cosine_similarity([vec_i], [vec_j])[0][0]\n",
    "        if sim >= limiar_remocao:\n",
    "            pares_similares.append((i, j, sim))\n",
    "            indices_para_remover.add(j)\n",
    "            if i not in agrupamento_similares:\n",
    "                agrupamento_similares[i] = []\n",
    "            agrupamento_similares[i].append(j)\n",
    "\n",
    "# --- Etapa 4: Somar frequências das mensagens similares ---\n",
    "for idx_base, indices_duplicados in agrupamento_similares.items():\n",
    "    freq_original = df.at[idx_base, 'frequencia']\n",
    "    soma = sum(df.loc[dup_idx, 'frequencia'] for dup_idx in indices_duplicados)\n",
    "    df.at[idx_base, 'frequencia'] = freq_original + soma\n",
    "\n",
    "# --- Etapa 5: Remover duplicadas ---\n",
    "df = df.drop(index=list(indices_para_remover)).reset_index(drop=True)\n",
    "\n",
    "# --- Etapa 6: Visualizar resultado final ---\n",
    "print(f\"\\nMensagens agrupadas por similaridade (≥ {limiar_remocao}):\\n\")\n",
    "for i, j, sim in sorted(pares_similares, key=lambda x: -x[2]):\n",
    "    print(f\"Similaridade: {sim:.4f}\")\n",
    "    print(f\"A (mantida): {df.iloc[i]['texto_limpo']}\")\n",
    "    print(f\"B (removida): {df.iloc[j]['texto_limpo']}\\n\")\n",
    "\n",
    "print(\"\\n### DataFrame final:\")\n",
    "print(df[['texto_original', 'frequencia']])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
