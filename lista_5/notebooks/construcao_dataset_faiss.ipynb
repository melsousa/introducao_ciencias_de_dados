{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d40530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0423445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/fakeTelegram_SemTravaZap_BR_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fff565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557515, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbce4156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date_message', 'id_member_anonymous',\n",
       "       'id_group_anonymous', 'media', 'media_type', 'media_url', 'has_media',\n",
       "       'has_media_url', 'trava_zap', 'text_content_anonymous',\n",
       "       'dataset_info_id', 'date_system', 'score_sentiment',\n",
       "       'score_misinformation', 'id_message', 'message_type', 'messenger',\n",
       "       'media_name', 'media_md5', 'caracteres_especial_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32c06764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     int64\n",
       "date_message                  object\n",
       "id_member_anonymous           object\n",
       "id_group_anonymous            object\n",
       "media                         object\n",
       "media_type                    object\n",
       "media_url                     object\n",
       "has_media                       bool\n",
       "has_media_url                   bool\n",
       "trava_zap                       bool\n",
       "text_content_anonymous        object\n",
       "dataset_info_id                int64\n",
       "date_system                   object\n",
       "score_sentiment              float64\n",
       "score_misinformation         float64\n",
       "id_message                     int64\n",
       "message_type                  object\n",
       "messenger                     object\n",
       "media_name                    object\n",
       "media_md5                     object\n",
       "caracteres_especial_count      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d8bd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444146, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluir as linhas onde 'text_content_anonymous' Ã© nula, modificando o dataframe original\n",
    "df.dropna(subset=['text_content_anonymous'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec01e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_content_anonymous\n",
       "This community was blocked in Brazil following a decision of the Superior Electoral Court (TSE).                                                                                                                                                                                                                                                                         17422\n",
       "Rough_sexğŸ™ˆ                                                                                                                                                                                                                                                                                                                                                                1134\n",
       "Anal sexğŸ™ˆ                                                                                                                                                                                                                                                                                                                                                                 1118\n",
       "Ø³Ú©Ø³ Ù…Ø±Ø¯Ø§Ù† Ø§Ø²Ø¨Ú© Ø¨Ø§ Ø²Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø§ Ø§ÛŒÙ† vpn Ø§Ø² Ø³Ø§ÛŒØªÙ‡Ø§ÛŒ Ù…Ù…Ù†ÙˆØ¹Ù‡ Ø¨Ø¨ÛŒÙ†ÛŒØ¯ğŸ™ˆ\\n\\nØ´Ø§Ù‡Ø¯ Ø§Ù„Ø±Ø¬Ø§Ù„ Ø§Ù„Ø£ÙˆØ²Ø¨ÙƒÙŠÙŠÙ† ÙŠÙ…Ø§Ø±Ø³ÙˆÙ† Ø§Ù„Ø¬Ù†Ø³ Ù…Ø¹ Ø§Ù„Ù†Ø³Ø§Ø¡ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… VPN Ù‡Ø°Ø§ Ù…Ù† Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©ğŸš«\\n\\nTaqiqlangan saytlardan bu vpn orqali o'zbek erkaklari ingliz ayollari bilan jinsiy aloqa qilishlarini ko'ring\\n\\nSee Uzbek men having sex with English women with this vpn from banned sites     1019\n",
       "https://youtu.be/qbTzhB0akt8                                                                                                                                                                                                                                                                                                                                               758\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_count = df['text_content_anonymous'].value_counts()\n",
    "message_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c633eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_count_df = message_count.reset_index()\n",
    "message_count_df.columns = ['text_content_anonymous', 'frequencia']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6dfe1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265313, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_count_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a261f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222351, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_count_df = message_count_df[message_count_df['text_content_anonymous'].str.strip().str.split().apply(lambda x: len([w for w in x if w])) >= 5]\n",
    "message_count_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "855f7ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import unidecode\n",
    "\n",
    "def limpar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"http\\S+\", \"\", texto)  # remove URLs\n",
    "    texto = emoji.replace_emoji(texto, '')  # remove emojis\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", texto)  # remove pontuaÃ§Ã£o\n",
    "    texto = unidecode.unidecode(texto)  # remove acentos\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "    return texto\n",
    "\n",
    "message_count_df['texto_limpo'] = message_count_df['text_content_anonymous'].apply(limpar_texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bd2ad49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_content_anonymous</th>\n",
       "      <th>frequencia</th>\n",
       "      <th>texto_limpo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This community was blocked in Brazil following...</td>\n",
       "      <td>17422</td>\n",
       "      <td>this community was blocked in brazil following...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø³Ú©Ø³ Ù…Ø±Ø¯Ø§Ù† Ø§Ø²Ø¨Ú© Ø¨Ø§ Ø²Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø§ Ø§ÛŒÙ† vpn Ø§Ø² Ø³Ø§ÛŒ...</td>\n",
       "      <td>1019</td>\n",
       "      <td>vpn vpn taqiqlangan saytlardan bu vpn orqali o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ÙÛŒÙ„Ù… Ø³ÙˆÙ¾Ø± Ø¨Ø§ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ ÙØ§Ø±Ø³ÛŒ Ø¨Ø¨ÛŒÙ†ğŸ˜ğŸ˜\\nØ¨Ø§ Ø§ÛŒÙ† ÙÛŒÙ„Øª...</td>\n",
       "      <td>632</td>\n",
       "      <td>amerikalik ayolni arab erkaklari tomonidan zor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We had no choice but to remain in the shadows....</td>\n",
       "      <td>480</td>\n",
       "      <td>we had no choice but to remain in the shadows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://t.me/canalselvabrasiloficial\\nSELVA BR...</td>\n",
       "      <td>461</td>\n",
       "      <td>selva brasil oficial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ğŸ‡®ğŸ‡· Ø³Ú©Ø³ Ø¨Ø§ Ø¯Ø®ØªØ± 14 Ø³Ø§Ù„Ù‡ Ø±Ø§ Ø¯Ø± Ø³Ø§ÛŒØªÙ‡Ø§ÛŒ Ù¾ÙˆØ±Ù†\\nØ¨ÛŒÛŒ...</td>\n",
       "      <td>400</td>\n",
       "      <td>14 vpn watch sex with a 14yearold girl on porn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"E conhecereis a verdade, e a verdade vos libe...</td>\n",
       "      <td>367</td>\n",
       "      <td>e conhecereis a verdade e a verdade vos libert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bem vindo(a) ao grupo IpirÃ¡ NotÃ­cias. \\n\\nComp...</td>\n",
       "      <td>358</td>\n",
       "      <td>bem vindoa ao grupo ipir notcias compartilhe n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>VÃ­deo de AVANY FERREIRA MULLER</td>\n",
       "      <td>195</td>\n",
       "      <td>vdeo de avany ferreira muller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VÃ­deo de Maria Teresa D  Valente</td>\n",
       "      <td>189</td>\n",
       "      <td>vdeo de maria teresa d valente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Para quem gosta de MEDICINA NATURAL, esse Ã©, S...</td>\n",
       "      <td>186</td>\n",
       "      <td>para quem gosta de medicina natural esse sem d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Foto de Maria Teresa D  Valente</td>\n",
       "      <td>184</td>\n",
       "      <td>foto de maria teresa d valente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>O Meu amigo NÃƒO sou infiltrado ... meu voto fo...</td>\n",
       "      <td>172</td>\n",
       "      <td>o meu amigo no sou infiltrado meu voto foi par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VÃ­deo de R A S G A N D O</td>\n",
       "      <td>171</td>\n",
       "      <td>vdeo de r a s g a n d o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Grupo Para Organizar 200 MIL Eleitores do Bols...</td>\n",
       "      <td>152</td>\n",
       "      <td>grupo para organizar 200 mil eleitores do bols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>INVISTA CONOSCO E RECEBAâœ…\\n SEU LUCRO ESTÃ SEG...</td>\n",
       "      <td>130</td>\n",
       "      <td>invista conosco e receba seu lucro est seguro ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BOA NOITE A TODOS. O QUE EU VOU DIZER Ã‰ SÃ‰RIO ...</td>\n",
       "      <td>127</td>\n",
       "      <td>boa noite a todos o que eu vou dizer srio a es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Regras do Grupo \\n\\n1Â° Regra do grupo Ã© respei...</td>\n",
       "      <td>127</td>\n",
       "      <td>regras do grupo 1 regra do grupo respeito aos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ğŸŒ’ ENCERRAR MODO NOTURNO\\n\\nâœ… De agora em diant...</td>\n",
       "      <td>117</td>\n",
       "      <td>encerrar modo noturno de agora em diante os us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NotÃ­cia de dentro do quartel. Os militares JÃ ...</td>\n",
       "      <td>116</td>\n",
       "      <td>notcia de dentro do quartel os militares j que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ğŸš¨Pessoal, estamos correndo contra o tempo para...</td>\n",
       "      <td>107</td>\n",
       "      <td>pessoal estamos correndo contra o tempo para i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>VÃ­deo de Jane M.A.Coletti â˜ºï¸ğŸ‡§ğŸ‡·ğŸ‡§ğŸ‡·ğŸ‡§ğŸ‡·</td>\n",
       "      <td>105</td>\n",
       "      <td>vdeo de jane macoletti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>VÃ­deo de Maria Emilia Gadelha Serr</td>\n",
       "      <td>103</td>\n",
       "      <td>vdeo de maria emilia gadelha serr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Desculpa, pessoal, eu sei que esse pode nÃ£o se...</td>\n",
       "      <td>99</td>\n",
       "      <td>desculpa pessoal eu sei que esse pode no ser o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>*VAMOS SEGUIR O INSTAGRAM DO EXÃ‰RCITO BRASILEI...</td>\n",
       "      <td>98</td>\n",
       "      <td>vamos seguir o instagram do exrcito brasileiro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>JÃ¡ que lula colocou um milhÃ£o no podcast do fl...</td>\n",
       "      <td>97</td>\n",
       "      <td>j que lula colocou um milho no podcast do flow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>VÃ­deo de Paulo Roberto Schuster</td>\n",
       "      <td>97</td>\n",
       "      <td>vdeo de paulo roberto schuster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Ola pessoal acessem o nosso grupo. \\nâœ…Sem ofen...</td>\n",
       "      <td>96</td>\n",
       "      <td>ola pessoal acessem o nosso grupo sem ofensas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ğŸŒ’ MODO NOTURNO INICIADO\\n\\nâŒ A partir deste mo...</td>\n",
       "      <td>94</td>\n",
       "      <td>modo noturno iniciado a partir deste momento a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ğ‡ğğ‹ğƒ ğğ, ğ‹ğ„ğ“ ğŒğ„ ğ‘ğ”ğ ğ€ ğ‚ğ‡ğ„ğ‚ğŠ ğ“ğ ğ‚ğğŒğ…ğˆğ‘ğŒ ğ˜ğğ”ğ‘ ğğ€...</td>\n",
       "      <td>93</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text_content_anonymous  frequencia  \\\n",
       "0   This community was blocked in Brazil following...       17422   \n",
       "3   Ø³Ú©Ø³ Ù…Ø±Ø¯Ø§Ù† Ø§Ø²Ø¨Ú© Ø¨Ø§ Ø²Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø§ Ø§ÛŒÙ† vpn Ø§Ø² Ø³Ø§ÛŒ...        1019   \n",
       "6   ÙÛŒÙ„Ù… Ø³ÙˆÙ¾Ø± Ø¨Ø§ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ ÙØ§Ø±Ø³ÛŒ Ø¨Ø¨ÛŒÙ†ğŸ˜ğŸ˜\\nØ¨Ø§ Ø§ÛŒÙ† ÙÛŒÙ„Øª...         632   \n",
       "9   We had no choice but to remain in the shadows....         480   \n",
       "11  https://t.me/canalselvabrasiloficial\\nSELVA BR...         461   \n",
       "14  ğŸ‡®ğŸ‡· Ø³Ú©Ø³ Ø¨Ø§ Ø¯Ø®ØªØ± 14 Ø³Ø§Ù„Ù‡ Ø±Ø§ Ø¯Ø± Ø³Ø§ÛŒØªÙ‡Ø§ÛŒ Ù¾ÙˆØ±Ù†\\nØ¨ÛŒÛŒ...         400   \n",
       "19  \"E conhecereis a verdade, e a verdade vos libe...         367   \n",
       "21  Bem vindo(a) ao grupo IpirÃ¡ NotÃ­cias. \\n\\nComp...         358   \n",
       "28                     VÃ­deo de AVANY FERREIRA MULLER         195   \n",
       "30                   VÃ­deo de Maria Teresa D  Valente         189   \n",
       "31  Para quem gosta de MEDICINA NATURAL, esse Ã©, S...         186   \n",
       "32                    Foto de Maria Teresa D  Valente         184   \n",
       "34  O Meu amigo NÃƒO sou infiltrado ... meu voto fo...         172   \n",
       "35                           VÃ­deo de R A S G A N D O         171   \n",
       "41  Grupo Para Organizar 200 MIL Eleitores do Bols...         152   \n",
       "47  INVISTA CONOSCO E RECEBAâœ…\\n SEU LUCRO ESTÃ SEG...         130   \n",
       "48  BOA NOITE A TODOS. O QUE EU VOU DIZER Ã‰ SÃ‰RIO ...         127   \n",
       "50  Regras do Grupo \\n\\n1Â° Regra do grupo Ã© respei...         127   \n",
       "53  ğŸŒ’ ENCERRAR MODO NOTURNO\\n\\nâœ… De agora em diant...         117   \n",
       "54  NotÃ­cia de dentro do quartel. Os militares JÃ ...         116   \n",
       "59  ğŸš¨Pessoal, estamos correndo contra o tempo para...         107   \n",
       "60                 VÃ­deo de Jane M.A.Coletti â˜ºï¸ğŸ‡§ğŸ‡·ğŸ‡§ğŸ‡·ğŸ‡§ğŸ‡·         105   \n",
       "63                 VÃ­deo de Maria Emilia Gadelha Serr         103   \n",
       "68  Desculpa, pessoal, eu sei que esse pode nÃ£o se...          99   \n",
       "69  *VAMOS SEGUIR O INSTAGRAM DO EXÃ‰RCITO BRASILEI...          98   \n",
       "70  JÃ¡ que lula colocou um milhÃ£o no podcast do fl...          97   \n",
       "71                    VÃ­deo de Paulo Roberto Schuster          97   \n",
       "72  Ola pessoal acessem o nosso grupo. \\nâœ…Sem ofen...          96   \n",
       "73  ğŸŒ’ MODO NOTURNO INICIADO\\n\\nâŒ A partir deste mo...          94   \n",
       "75  ğ‡ğğ‹ğƒ ğğ, ğ‹ğ„ğ“ ğŒğ„ ğ‘ğ”ğ ğ€ ğ‚ğ‡ğ„ğ‚ğŠ ğ“ğ ğ‚ğğŒğ…ğˆğ‘ğŒ ğ˜ğğ”ğ‘ ğğ€...          93   \n",
       "\n",
       "                                          texto_limpo  \n",
       "0   this community was blocked in brazil following...  \n",
       "3   vpn vpn taqiqlangan saytlardan bu vpn orqali o...  \n",
       "6   amerikalik ayolni arab erkaklari tomonidan zor...  \n",
       "9   we had no choice but to remain in the shadows ...  \n",
       "11                               selva brasil oficial  \n",
       "14  14 vpn watch sex with a 14yearold girl on porn...  \n",
       "19  e conhecereis a verdade e a verdade vos libert...  \n",
       "21  bem vindoa ao grupo ipir notcias compartilhe n...  \n",
       "28                      vdeo de avany ferreira muller  \n",
       "30                     vdeo de maria teresa d valente  \n",
       "31  para quem gosta de medicina natural esse sem d...  \n",
       "32                     foto de maria teresa d valente  \n",
       "34  o meu amigo no sou infiltrado meu voto foi par...  \n",
       "35                            vdeo de r a s g a n d o  \n",
       "41  grupo para organizar 200 mil eleitores do bols...  \n",
       "47  invista conosco e receba seu lucro est seguro ...  \n",
       "48  boa noite a todos o que eu vou dizer srio a es...  \n",
       "50  regras do grupo 1 regra do grupo respeito aos ...  \n",
       "53  encerrar modo noturno de agora em diante os us...  \n",
       "54  notcia de dentro do quartel os militares j que...  \n",
       "59  pessoal estamos correndo contra o tempo para i...  \n",
       "60                             vdeo de jane macoletti  \n",
       "63                  vdeo de maria emilia gadelha serr  \n",
       "68  desculpa pessoal eu sei que esse pode no ser o...  \n",
       "69  vamos seguir o instagram do exrcito brasileiro...  \n",
       "70  j que lula colocou um milho no podcast do flow...  \n",
       "71                     vdeo de paulo roberto schuster  \n",
       "72  ola pessoal acessem o nosso grupo sem ofensas ...  \n",
       "73  modo noturno iniciado a partir deste momento a...  \n",
       "75                                                     "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_count_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ec84913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>222351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.525655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37.162584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17422.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          frequencia\n",
       "count  222351.000000\n",
       "mean        1.525655\n",
       "std        37.162584\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max     17422.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_count_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers faiss-cpu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1381c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gerando embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6721/6721 [5:39:47<00:00,  3.03s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Buscando vizinhos similares com FAISS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 215051/215051 [7:22:11<00:00,  8.11it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ Total de mensagens finais: 188264\n",
      "  Mensagens removidas por similaridade: 28664\n",
      "\n",
      " Mensagens finais:\n",
      "                                           texto_original  frequencia\n",
      "0       â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...          10\n",
      "1            *02.10.2022 TSE - Governo-SP Ã s 18h 59m 00s*           8\n",
      "2              02.10.2022 TSE - Governo-SP Ã s 20h 10m 35s           4\n",
      "3            02.10.2022 TSE - Presidente - Ã s 18h 55m 31s          10\n",
      "4            *02.10.2022 TSE - Presidente Ã s 20h 02m 45s*           3\n",
      "...                                                   ...         ...\n",
      "188259  â€˜Zum Zum Zumâ€™ em brasÃ³liaâ€¦\\n\\nA bem da paz soc...           1\n",
      "188260  ZUMBI NÃƒO ESCOLHE LUGAR PARA MORDER. O OBJETIV...           1\n",
      "188261  ZUMBIS MODIFICADOS NO DNA PELA VACINA.. NÃƒO SE...           2\n",
      "188262  ZuverlÃ¤ssige und vertrauenswÃ¼rdige Zahlungssei...           1\n",
      "188263  Zyklon B era pra matar piolhos. A manipulaÃ§Ã£o ...           1\n",
      "\n",
      "[188264 rows x 2 columns]\n",
      "\n",
      " Agrupamentos realizados:\n",
      "                                              texto_base  \\\n",
      "0      â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...   \n",
      "1      â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...   \n",
      "2      â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...   \n",
      "3      â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...   \n",
      "4      â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...   \n",
      "...                                                  ...   \n",
      "28659  Zero Float TP1// 25pips âœ…\\n\\nLets secure half ...   \n",
      "28660  Zero Float TP1// 25pips âœ…\\n\\nLets secure half ...   \n",
      "28661  Zero float TP1//20pipsâœ…\\n\\nLetâ€™s take our quic...   \n",
      "28662  Zildinha, pressione o botÃ£o abaixo dentro de 3...   \n",
      "28663  Zoorg moda em couro . [781773523] uso excessiv...   \n",
      "\n",
      "                                           texto_similar  frequencia_similar  \n",
      "0      â–ªï¸ 03/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...                   1  \n",
      "1      â–ªï¸ 07/10/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...                   1  \n",
      "2      â–ªï¸ 10/10/2022 - 08:01 \\n\\nÃsia-PacÃ­fico (fecha...                   1  \n",
      "3      â–ªï¸ 06/10/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...                   1  \n",
      "4      â–ªï¸ 04/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...                   1  \n",
      "...                                                  ...                 ...  \n",
      "28659  Zero Float TP1//42pips âœ…\\n\\nLets secure half p...                   1  \n",
      "28660  Zero Float TP1//25pipsâœ…\\n\\nLets secure our pro...                   1  \n",
      "28661  zero float TP1//30pipsâœ…\\n\\nAs usual, letâ€™s sca...                   1  \n",
      "28662  Zâ™¥ï¸aâ™¥ï¸hâ™¥ï¸râ™¥ï¸a, pressione o botÃ£o abaixo dentro...                   1  \n",
      "28663  Zoorg moda em couro . [781773523] uso excessiv...                   1  \n",
      "\n",
      "[28664 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3. Agrupar por texto normalizado\n",
    "# ================================\n",
    "\n",
    "df_agrupado = (\n",
    "    message_count_df.groupby('texto_limpo')\n",
    "          .agg({\n",
    "              'frequencia': 'sum',\n",
    "              'text_content_anonymous': lambda x: x.mode().iloc[0]  # pega texto original mais comum\n",
    "          })\n",
    "          .reset_index()\n",
    "          .rename(columns={'text_content_anonymous': 'texto_original'})\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 4. Embeddings\n",
    "# ================================\n",
    "print(\" Gerando embeddings...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings_orig = model.encode(df_agrupado['texto_limpo'].tolist(), show_progress_bar=True)\n",
    "df_agrupado['vector'] = embeddings_orig.tolist()\n",
    "\n",
    "# ================================\n",
    "# 5. IndexaÃ§Ã£o com FAISS\n",
    "# ================================\n",
    "embeddings = np.array(embeddings_orig.copy())\n",
    "dimension = embeddings.shape[1]\n",
    "faiss.normalize_L2(embeddings)\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# ================================\n",
    "# 6. Busca por vizinhos\n",
    "# ================================\n",
    "limiar_similaridade = 0.90\n",
    "k = 10\n",
    "\n",
    "print(\" Buscando vizinhos similares com FAISS...\")\n",
    "agrupamento = defaultdict(list)\n",
    "indices_para_remover = set()\n",
    "\n",
    "for i in tqdm(range(len(df_agrupado))):\n",
    "    if i in indices_para_remover:\n",
    "        continue\n",
    "    vec = embeddings[i].reshape(1, -1).copy()\n",
    "    D, I = index.search(vec, k)\n",
    "    for sim, j in zip(D[0][1:], I[0][1:]):\n",
    "        if j == -1 or j == i or j in indices_para_remover:\n",
    "            continue\n",
    "        if sim >= limiar_similaridade:\n",
    "            agrupamento[i].append(j)\n",
    "            indices_para_remover.add(j)\n",
    "\n",
    "# ================================\n",
    "# 7. Consolidar agrupamentos\n",
    "# ================================\n",
    "linhas_resultado = []\n",
    "mensagens_utilizadas = set()\n",
    "linhas_agrupadas = []\n",
    "\n",
    "for idx_base, similares_idxs in agrupamento.items():\n",
    "    if idx_base in mensagens_utilizadas:\n",
    "        continue\n",
    "    freq_total = df_agrupado.iloc[idx_base]['frequencia']\n",
    "    mensagens_utilizadas.add(idx_base)\n",
    "\n",
    "    for sim_idx in similares_idxs:\n",
    "        freq_total += df_agrupado.iloc[sim_idx]['frequencia']\n",
    "        mensagens_utilizadas.add(sim_idx)\n",
    "        linhas_agrupadas.append({\n",
    "            'texto_base': df_agrupado.iloc[idx_base]['texto_original'],\n",
    "            'texto_similar': df_agrupado.iloc[sim_idx]['texto_original'],\n",
    "            'frequencia_similar': df_agrupado.iloc[sim_idx]['frequencia']\n",
    "        })\n",
    "\n",
    "    linha = df_agrupado.iloc[idx_base].copy()\n",
    "    linha['frequencia'] = freq_total\n",
    "    linhas_resultado.append(linha)\n",
    "\n",
    "# Adiciona nÃ£o agrupados\n",
    "indices_restantes = set(range(len(df_agrupado))) - mensagens_utilizadas\n",
    "df_restantes = df_agrupado.iloc[list(indices_restantes)].copy()\n",
    "\n",
    "# Resultados finais\n",
    "df_resultado = pd.DataFrame(linhas_resultado)\n",
    "df_final_total = pd.concat([df_resultado, df_restantes], ignore_index=True)\n",
    "df_agrupadas = pd.DataFrame(linhas_agrupadas)\n",
    "\n",
    "# ================================\n",
    "# 8. Exibir resultados\n",
    "# ================================\n",
    "print(f\"\\ Total de mensagens finais: {len(df_final_total)}\")\n",
    "print(f\"  Mensagens removidas por similaridade: {len(indices_para_remover)}\")\n",
    "\n",
    "print(\"\\n Mensagens finais:\")\n",
    "print(df_final_total[['texto_original', 'frequencia']])\n",
    "\n",
    "print(\"\\n Agrupamentos realizados:\")\n",
    "print(df_agrupadas)\n",
    "\n",
    "# ================================\n",
    "# 9. Salvar com vetores\n",
    "# ================================\n",
    "\n",
    "# O vetor jÃ¡ estÃ¡ na coluna 'vector' de df_final_total\n",
    "df_final_total[['texto_original', 'frequencia', 'vector']].to_pickle(\"mensagens_com_vectores.pkl\")\n",
    "\n",
    "# (opcional) salvar em CSV sem os vetores\n",
    "df_final_total[['texto_original', 'frequencia']].to_csv(\"mensagens_com_frequencia.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8e126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_content_anonymous</th>\n",
       "      <th>frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"E conhecereis a verdade, e a verdade vos libe...</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VÃ­deo de Maria Teresa D  Valente</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Regras do Grupo \\n\\n1Â° Regra do grupo Ã© respei...</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VÃ­deo de Maria Emilia Gadelha Serr</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ola! Tudo bem? A nossa enquete eleitoral esta ...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text_content_anonymous  frequencia\n",
       "6   \"E conhecereis a verdade, e a verdade vos libe...         426\n",
       "9                    VÃ­deo de Maria Teresa D  Valente         373\n",
       "17  Regras do Grupo \\n\\n1Â° Regra do grupo Ã© respei...         208\n",
       "22                 VÃ­deo de Maria Emilia Gadelha Serr         150\n",
       "36  Ola! Tudo bem? A nossa enquete eleitoral esta ...         149"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1e1e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_original</th>\n",
       "      <th>frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*02.10.2022 TSE - Governo-SP Ã s 18h 59m 00s*</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02.10.2022 TSE - Governo-SP Ã s 20h 10m 35s</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02.10.2022 TSE - Presidente - Ã s 18h 55m 31s</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*02.10.2022 TSE - Presidente Ã s 20h 02m 45s*</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      texto_original  frequencia\n",
       "0  â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...          10\n",
       "1       *02.10.2022 TSE - Governo-SP Ã s 18h 59m 00s*           8\n",
       "2         02.10.2022 TSE - Governo-SP Ã s 20h 10m 35s           4\n",
       "3       02.10.2022 TSE - Presidente - Ã s 18h 55m 31s          10\n",
       "4       *02.10.2022 TSE - Presidente Ã s 20h 02m 45s*           3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clear = pd.read_csv('mensagens_com_frequencia.csv')\n",
    "df_clear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74b9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "# --- FunÃ§Ã£o para limpar texto ---\n",
    "def limpar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"http\\S+\", \"\", texto)  # remove URLs\n",
    "    texto = emoji.replace_emoji(texto, '')  # remove emojis\n",
    "    texto = unidecode.unidecode(texto)  # substitui acentos\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", texto)  # remove pontuaÃ§Ã£o\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()  # remove espaÃ§os extras\n",
    "    return texto\n",
    "\n",
    "# AplicaÃ§Ã£o da funÃ§Ã£o na coluna\n",
    "df_clear['texto_limpo'] = df_clear['texto_original'].apply(limpar_texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b09a3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_original</th>\n",
       "      <th>frequencia</th>\n",
       "      <th>texto_limpo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...</td>\n",
       "      <td>10</td>\n",
       "      <td>01112022 0800 asiapacifico fechado spasx 165 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*02.10.2022 TSE - Governo-SP Ã s 18h 59m 00s*</td>\n",
       "      <td>8</td>\n",
       "      <td>02102022 tse governosp as 18h 59m 00s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02.10.2022 TSE - Governo-SP Ã s 20h 10m 35s</td>\n",
       "      <td>4</td>\n",
       "      <td>02102022 tse governosp as 20h 10m 35s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02.10.2022 TSE - Presidente - Ã s 18h 55m 31s</td>\n",
       "      <td>10</td>\n",
       "      <td>02102022 tse presidente as 18h 55m 31s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*02.10.2022 TSE - Presidente Ã s 20h 02m 45s*</td>\n",
       "      <td>3</td>\n",
       "      <td>02102022 tse presidente as 20h 02m 45s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      texto_original  frequencia  \\\n",
       "0  â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...          10   \n",
       "1       *02.10.2022 TSE - Governo-SP Ã s 18h 59m 00s*           8   \n",
       "2         02.10.2022 TSE - Governo-SP Ã s 20h 10m 35s           4   \n",
       "3       02.10.2022 TSE - Presidente - Ã s 18h 55m 31s          10   \n",
       "4       *02.10.2022 TSE - Presidente Ã s 20h 02m 45s*           3   \n",
       "\n",
       "                                         texto_limpo  \n",
       "0  01112022 0800 asiapacifico fechado spasx 165 6...  \n",
       "1              02102022 tse governosp as 18h 59m 00s  \n",
       "2              02102022 tse governosp as 20h 10m 35s  \n",
       "3             02102022 tse presidente as 18h 55m 31s  \n",
       "4             02102022 tse presidente as 20h 02m 45s  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15688c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # FunÃ§Ã£o para extrair e substituir o domÃ­nio da URL\n",
    "    def substituir_dominios(texto):\n",
    "        # FunÃ§Ã£o para extrair e substituir o domÃ­nio da URL\n",
    "        def extrair_dominio(url):\n",
    "            # Remove o protocolo (http://, https://, etc.) e o \"www.\" se presente\n",
    "            dominio = re.sub(r'^https?://(?:www\\.)?|www\\.', '', url)\n",
    "            # Remove o caminho e parÃ¢metros da URL\n",
    "            dominio = re.split(r'[/?#]', dominio)[0]\n",
    "            # Retorna a parte principal do domÃ­nio (antes do primeiro ponto)\n",
    "            return dominio.split('.')[0]\n",
    "\n",
    "        # Substitui URLs por seus domÃ­nios principais\n",
    "        return re.sub(r'https?://(?:www\\.)?\\S+|www\\.\\S+', lambda match: extrair_dominio(match.group(0)), texto)\n",
    "\n",
    "    # Substituir domÃ­nios\n",
    "    text = substituir_dominios(text)\n",
    "\n",
    "    # Converte para minÃºsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove acentos\n",
    "    text = unidecode(text)\n",
    "\n",
    "    #Remover PontuaÃ§Ã£o\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove URLs e menÃ§Ãµes\n",
    "    #text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\w+', '', text)\n",
    "\n",
    "    # Substitui emojis repetidos por apenas um\n",
    "    text = re.sub(r'([\\U00010000-\\U0010FFFF])\\1+', r'\\1', text)\n",
    "    text = re.sub(r'([\\U0001F600-\\U0001F64F]|[\\U0001F300-\\U0001F5FF]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F780-\\U0001F7FF]|[\\U0001F800-\\U0001F8FF]|[\\U0001F900-\\U0001F9FF]|[\\U0001FA00-\\U0001FA6F]|[\\U0001FA70-\\U0001FAFF])\\1+', r'\\1', text)\n",
    "\n",
    "\n",
    "    # Remove espaÃ§os em branco extras (inÃ­cio ou final) e mÃºltiplos espaÃ§os no meio do texto\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Remove pontuaÃ§Ãµes e caracteres especiais\n",
    "    #text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Ajusta risadas \"kkk\" ou mais para \"kk\"\n",
    "    text = re.sub(r'k{2,}|K{2,}', 'kk', text)\n",
    "\n",
    "    # Ajusta risadas \"haha\" ou mais para \"haha\"\n",
    "    text = re.sub(r'(ha){2,}', 'haha', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Ajusta risadas \"kaka\" ou mais para \"kaka\"\n",
    "    text = re.sub(r'(ka){2,}', 'kaka', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove as stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "dfcp = df_clear.copy()\n",
    "\n",
    "# Aplicar o prÃ©-processamento Ã  coluna de texto\n",
    "dfcp['text_processed'] = dfcp['texto_original'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d88b942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_original</th>\n",
       "      <th>frequencia</th>\n",
       "      <th>texto_limpo</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...</td>\n",
       "      <td>10</td>\n",
       "      <td>01112022 0800 asiapacifico fechado spasx 165 6...</td>\n",
       "      <td>01112022 0800 asiapacifico fechado spasx 165 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*02.10.2022 TSE - Governo-SP Ã s 18h 59m 00s*</td>\n",
       "      <td>8</td>\n",
       "      <td>02102022 tse governosp as 18h 59m 00s</td>\n",
       "      <td>02102022 tse governosp 18h 59m 00s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02.10.2022 TSE - Governo-SP Ã s 20h 10m 35s</td>\n",
       "      <td>4</td>\n",
       "      <td>02102022 tse governosp as 20h 10m 35s</td>\n",
       "      <td>02102022 tse governosp 20h 10m 35s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02.10.2022 TSE - Presidente - Ã s 18h 55m 31s</td>\n",
       "      <td>10</td>\n",
       "      <td>02102022 tse presidente as 18h 55m 31s</td>\n",
       "      <td>02102022 tse presidente 18h 55m 31s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*02.10.2022 TSE - Presidente Ã s 20h 02m 45s*</td>\n",
       "      <td>3</td>\n",
       "      <td>02102022 tse presidente as 20h 02m 45s</td>\n",
       "      <td>02102022 tse presidente 20h 02m 45s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      texto_original  frequencia  \\\n",
       "0  â–ªï¸ 01/11/2022 - 08:00 \\n\\nÃsia-PacÃ­fico (fecha...          10   \n",
       "1       *02.10.2022 TSE - Governo-SP Ã s 18h 59m 00s*           8   \n",
       "2         02.10.2022 TSE - Governo-SP Ã s 20h 10m 35s           4   \n",
       "3       02.10.2022 TSE - Presidente - Ã s 18h 55m 31s          10   \n",
       "4       *02.10.2022 TSE - Presidente Ã s 20h 02m 45s*           3   \n",
       "\n",
       "                                         texto_limpo  \\\n",
       "0  01112022 0800 asiapacifico fechado spasx 165 6...   \n",
       "1              02102022 tse governosp as 18h 59m 00s   \n",
       "2              02102022 tse governosp as 20h 10m 35s   \n",
       "3             02102022 tse presidente as 18h 55m 31s   \n",
       "4             02102022 tse presidente as 20h 02m 45s   \n",
       "\n",
       "                                      text_processed  \n",
       "0  01112022 0800 asiapacifico fechado spasx 165 6...  \n",
       "1                 02102022 tse governosp 18h 59m 00s  \n",
       "2                 02102022 tse governosp 20h 10m 35s  \n",
       "3                02102022 tse presidente 18h 55m 31s  \n",
       "4                02102022 tse presidente 20h 02m 45s  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca465c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcp.to_csv('../dataset/mensagens_com_frequencia_e_texto_processado.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
